{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df39bf0c-4160-4c0c-9e0f-7e0a19bd3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.amp import autocast, GradScaler\n",
    "from copy import deepcopy\n",
    "from contextlib import nullcontext\n",
    "\n",
    "# ----------------- Âü∫Á°ÄÈÖçÁΩÆ -----------------\n",
    "# Tiny-ImageNet Âõ∫ÂÆö 200 Á±ªÔºàÂèØÁî®ÁéØÂ¢ÉÂèòÈáèË¶ÜÁõñÔºâ\n",
    "NUM_CLASSES = int(os.environ.get(\"NUM_CLASSES\", \"200\"))\n",
    "\n",
    "cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ebb75f-1b4e-4c82-aaec-af20654f8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_main_process():\n",
    "    return True\n",
    "\n",
    "\n",
    "def setup_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# ----------------- EMA Â∑•ÂÖ∑ -----------------\n",
    "def create_ema_model(model):\n",
    "    ema = deepcopy(model)\n",
    "    for p in ema.parameters():\n",
    "        p.requires_grad_(False)\n",
    "    ema.eval()\n",
    "    return ema\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def update_ema(model, ema_model, decay: float):\n",
    "    # Êõ¥Á®≥ÔºöË∑≥ËøáÈùûÊµÆÁÇπÂèÇÊï∞/ÁºìÂÜ≤ÔºõÊîØÊåÅ bf16/fp16/fp32 Ê∑∑Âêà\n",
    "    msd = model.state_dict()\n",
    "    esd = ema_model.state_dict()\n",
    "    for k, v in esd.items():\n",
    "        if k not in msd:\n",
    "            continue\n",
    "        src = msd[k]\n",
    "        if not torch.is_floating_point(v) or not torch.is_floating_point(src):\n",
    "            v.copy_(src)\n",
    "        else:\n",
    "            v.copy_(v * decay + src.detach() * (1.0 - decay))\n",
    "\n",
    "\n",
    "# ----------------- Mixup / CutMix -----------------\n",
    "def rand_bbox(W, H, lam):\n",
    "    cut_rat = (1.0 - lam) ** 0.5\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    x1 = int(np.clip(cx - cut_w // 2, 0, W))\n",
    "    y1 = int(np.clip(cy - cut_h // 2, 0, H))\n",
    "    x2 = int(np.clip(cx + cut_w // 2, 0, W))\n",
    "    y2 = int(np.clip(cy + cut_h // 2, 0, H))\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "\n",
    "def apply_mixup_cutmix(\n",
    "    x: torch.Tensor,\n",
    "    y: torch.Tensor,\n",
    "    mixup_alpha: float = 0.0,\n",
    "    cutmix_alpha: float = 0.0,\n",
    "    prob: float = 0.0,\n",
    "    switch_prob: float = 0.5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      x_mixed, y_a, y_b, lam, mixed\n",
    "    - If not mixed: y_b == y_a, lam=1.0, mixed=False\n",
    "    \"\"\"\n",
    "    if prob <= 0.0 or (mixup_alpha <= 0.0 and cutmix_alpha <= 0.0):\n",
    "        return x, y, y, 1.0, False\n",
    "\n",
    "    if np.random.rand() > prob:\n",
    "        return x, y, y, 1.0, False\n",
    "\n",
    "    bs = x.size(0)\n",
    "    device = x.device\n",
    "    perm = torch.randperm(bs, device=device)\n",
    "    y_a = y\n",
    "    y_b = y[perm]\n",
    "\n",
    "    use_cutmix = (np.random.rand() < switch_prob) and (cutmix_alpha > 0.0)\n",
    "    if use_cutmix:\n",
    "        lam = float(np.random.beta(cutmix_alpha, cutmix_alpha))\n",
    "        _, _, H, W = x.size()\n",
    "        x1, y1, x2, y2 = rand_bbox(W, H, lam)\n",
    "\n",
    "        x_mixed = x.clone()\n",
    "        x_mixed[:, :, y1:y2, x1:x2] = x[perm, :, y1:y2, x1:x2]\n",
    "\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "        lam_adj = 1.0 - float(area) / float(W * H)  # adjust by true mixed area\n",
    "        return x_mixed, y_a, y_b, lam_adj, True\n",
    "    else:\n",
    "        lam = float(np.random.beta(mixup_alpha, mixup_alpha))\n",
    "        x_mixed = x * lam + x[perm] * (1.0 - lam)\n",
    "        return x_mixed, y_a, y_b, lam, True\n",
    "\n",
    "\n",
    "def soft_target_loss(\n",
    "    logits: torch.Tensor,\n",
    "    y_a: torch.Tensor,\n",
    "    y_b: torch.Tensor,\n",
    "    lam: float,\n",
    "    label_smooth: float = 0.0,\n",
    "    mixed: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Cross-entropy with optional label smoothing, supports mixup/cutmix by linear combination.\n",
    "    \"\"\"\n",
    "    # PyTorch supports label_smoothing for cross_entropy in recent versions.\n",
    "    # Provide a safe fallback if unavailable.\n",
    "    def ce(pred, target):\n",
    "        try:\n",
    "            return F.cross_entropy(pred, target, label_smoothing=label_smooth)\n",
    "        except TypeError:\n",
    "            # manual label smoothing\n",
    "            if label_smooth <= 0:\n",
    "                return F.cross_entropy(pred, target)\n",
    "            num_classes = pred.size(1)\n",
    "            log_probs = F.log_softmax(pred, dim=1)\n",
    "            nll = -log_probs.gather(1, target.unsqueeze(1)).squeeze(1)\n",
    "            smooth = -log_probs.mean(dim=1)\n",
    "            return ((1.0 - label_smooth) * nll + label_smooth * smooth).mean()\n",
    "\n",
    "    if not mixed:\n",
    "        return ce(logits, y_a)\n",
    "    return lam * ce(logits, y_a) + (1.0 - lam) * ce(logits, y_b)\n",
    "\n",
    "\n",
    "def get_branch_alpha(epoch, start_epoch=30, ramp_epochs=30, alpha_max=1e-2):\n",
    "    if epoch < start_epoch:\n",
    "        return 0.0\n",
    "    t = min(1.0, (epoch - start_epoch) / max(1, ramp_epochs))\n",
    "    return alpha_max * t\n",
    "\n",
    "\n",
    "# ----------------- TinyImageNet Val Dataset -----------------\n",
    "class TinyImageNetVal(Dataset):\n",
    "    \"\"\"\n",
    "    ÂÖºÂÆπ tiny-imagenet-200 ÂéüÂßãÁõÆÂΩïÁªìÊûÑÔºö\n",
    "\n",
    "      tiny-imagenet-200/\n",
    "        train/<wnid>/images/*.JPEG\n",
    "        val/images/*.JPEG\n",
    "        val/val_annotations.txt   # ÊØèË°åÔºöimg\\twnid\\tx1\\ty1\\tx2\\ty2\n",
    "    \"\"\"\n",
    "    def __init__(self, val_root: str, class_to_idx: dict, transform=None):\n",
    "        self.val_root = val_root\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "        ann_path = os.path.join(val_root, \"val_annotations.txt\")\n",
    "        img_dir = os.path.join(val_root, \"images\")\n",
    "\n",
    "        if not os.path.isfile(ann_path):\n",
    "            raise FileNotFoundError(f\"val_annotations.txt not found at: {ann_path}\")\n",
    "        if not os.path.isdir(img_dir):\n",
    "            raise FileNotFoundError(f\"val/images not found at: {img_dir}\")\n",
    "\n",
    "        samples = []\n",
    "        with open(ann_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "                img_name, wnid = parts[0], parts[1]\n",
    "                if wnid not in class_to_idx:\n",
    "                    continue\n",
    "                path = os.path.join(img_dir, img_name)\n",
    "                target = class_to_idx[wnid]\n",
    "                samples.append((path, target))\n",
    "\n",
    "        if len(samples) == 0:\n",
    "            raise RuntimeError(\n",
    "                \"TinyImageNetVal found 0 samples. \"\n",
    "                \"ËØ∑Á°ÆËÆ§ TINYIMAGENET_ROOT ÊåáÂêë tiny-imagenet-200Ôºå‰∏î train/val ÁõÆÂΩïÂÆåÊï¥„ÄÇ\"\n",
    "            )\n",
    "\n",
    "        self.samples = samples\n",
    "        self.loader = default_loader\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        path, target = self.samples[idx]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "\n",
    "# ----------------- Optim param grouping -----------------\n",
    "def build_param_groups(model, base_lr, weight_decay, branch_lr_scale=1.0):\n",
    "    \"\"\"\n",
    "    ÂàÜÂõõÁªÑÔºömain_decay / main_no_decay / branch_decay / branch_no_decay\n",
    "    Âπ∂Âú® param_group ÈáåÊâìÊ†áÁ≠æÔºåÊñπ‰æø‰Ω†ÂêéÁª≠Âä®ÊÄÅÊîπ branch ÁöÑ weight_decay„ÄÇ\n",
    "    \"\"\"\n",
    "    no_wd = set()\n",
    "    if hasattr(model, \"no_weight_decay\"):\n",
    "        try:\n",
    "            no_wd = set(model.no_weight_decay())\n",
    "        except Exception:\n",
    "            no_wd = set()\n",
    "\n",
    "    # bias ‰∏ÄÂæã‰∏çÂÅö wd\n",
    "    for n, _p in model.named_parameters():\n",
    "        if n.endswith(\".bias\"):\n",
    "            no_wd.add(n)\n",
    "    # È¢ùÂ§ñÂª∫ËÆÆÔºöBatchNorm ÁöÑ weight ÈÄöÂ∏∏‰πü‰∏çÂÅö weight decayÔºàÊõ¥Á®≥‰∏Ä‰∫õÔºâ\n",
    "    for n, _p in model.named_parameters():\n",
    "        if \".bn\" in n and n.endswith(\".weight\"):\n",
    "            no_wd.add(n)\n",
    "\n",
    "\n",
    "    main_decay, main_no_decay = [], []\n",
    "    branch_decay, branch_no_decay = [], []\n",
    "\n",
    "    for n, p in model.named_parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "\n",
    "        is_branch = (\n",
    "            n.startswith(\"feature_extractor_branch\")\n",
    "            or n.startswith(\"head_adapter.proj\")\n",
    "            or n.startswith(\"gate_layer\")\n",
    "        )\n",
    "        is_no_wd = (n in no_wd)\n",
    "\n",
    "        if is_branch:\n",
    "            (branch_no_decay if is_no_wd else branch_decay).append(p)\n",
    "        else:\n",
    "            (main_no_decay if is_no_wd else main_decay).append(p)\n",
    "\n",
    "    groups = []\n",
    "    if main_decay:\n",
    "        groups.append({\"params\": main_decay, \"lr\": base_lr, \"weight_decay\": weight_decay, \"is_branch\": False, \"is_no_wd\": False})\n",
    "    if main_no_decay:\n",
    "        groups.append({\"params\": main_no_decay, \"lr\": base_lr, \"weight_decay\": 0.0, \"is_branch\": False, \"is_no_wd\": True})\n",
    "    if branch_decay:\n",
    "        groups.append({\"params\": branch_decay, \"lr\": base_lr * branch_lr_scale, \"weight_decay\": 0.0, \"is_branch\": True, \"is_no_wd\": False})\n",
    "    if branch_no_decay:\n",
    "        groups.append({\"params\": branch_no_decay, \"lr\": base_lr * branch_lr_scale, \"weight_decay\": 0.0, \"is_branch\": True, \"is_no_wd\": True})\n",
    "    return groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb5585ca-2a92-4d0c-bae3-33a0d12ead1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------- ‰∏ªÂÖ•Âè£ÔºàÂçïÊú∫ÂçïÂç°Ôºâ -----------------\n",
    "def main():\n",
    "    # ÂçïÊú∫ÂçïÂç°ÔºàÊàñ CPUÔºâËÆ≠ÁªÉÔºö‰∏ç‰ΩøÁî® DDP\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        torch.cuda.set_device(0)\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    setup_seed(int(os.environ.get(\"SEED\", \"42\")))\n",
    "\n",
    "    # AMP dtypeÔºàbf16 Êõ¥Á®≥Ôºõfp16 ÈÄüÂ∫¶Êõ¥Âø´‰ΩÜÊõ¥ÊïèÊÑüÔºâ\n",
    "    # ÁªèÈ™åÔºöÈÉ®ÂàÜ Windows + Ê∂àË¥πÁ∫ß GPU Âú® bf16 depthwise conv ‰∏ä‰ºöËß¶Âèë cuDNN ‚ÄúFIND was unable to find an engine‚Äù\n",
    "    # Âõ†Ê≠§ËøôÈáåÂÅö‰∏ÄÊ¨°Â∞èÊé¢ÈíàÔºöËã• bf16 ‰∏ã depthwise conv ‰∏çÂèØÁî®ÔºåÂàôËá™Âä®ÂõûÈÄÄÂà∞ fp16ÔºàÊàñÁî®Êà∑ÊòæÂºèÂÖ≥Èó≠ AMPÔºâ„ÄÇ\n",
    "    #amp_dtype_req = os.environ.get(\"AMP_DTYPE\", \"bf16\").lower().strip()\n",
    "    amp_dtype_req = os.environ.get(\"AMP_DTYPE\", \"fp16\").lower().strip()\n",
    "    \n",
    "    def _make_amp_ctx(_dtype):\n",
    "        if device.type != \"cuda\" or _dtype is None:\n",
    "            return nullcontext()\n",
    "        return autocast(\"cuda\", dtype=_dtype)\n",
    "\n",
    "    def _probe_depthwise_conv(_dtype) -> bool:\n",
    "        if device.type != \"cuda\" or _dtype is None:\n",
    "            return True\n",
    "        try:\n",
    "            # Â∞ΩÈáèÂ§çÁé∞‰Ω†ÁöÑ ViLLayer Èáå depthwise conv ÁöÑÂÖ∏ÂûãÂΩ¢ÊÄÅÔºögroups=channelsÔºåH=W‚âà8\n",
    "            for ch in (384, 768):\n",
    "                x = torch.randn(2, ch, 8, 8, device=device, dtype=torch.float16)\n",
    "                conv = torch.nn.Conv2d(ch, ch, kernel_size=3, padding=1, groups=ch, bias=False).to(device)\n",
    "                with autocast(\"cuda\", dtype=_dtype):\n",
    "                    y = conv(x)\n",
    "                _ = y.mean().item()\n",
    "            return True\n",
    "        except RuntimeError as e:\n",
    "            msg = str(e)\n",
    "            if (\"FIND was unable to find an engine\" in msg) or (\"unable to find an engine\" in msg.lower()):\n",
    "                return False\n",
    "            # ÂÖ∂‰ªñÈîôËØØ‰πüËßÜ‰∏∫‰∏çÂèØÁî®\n",
    "            return False\n",
    "\n",
    "    amp_autocast_dtype = None\n",
    "    if amp_dtype_req in (\"none\", \"no\", \"off\", \"fp32\"):\n",
    "        amp_autocast_dtype = None\n",
    "    elif amp_dtype_req == \"fp16\":\n",
    "        amp_autocast_dtype = torch.float16\n",
    "    else:\n",
    "        # ÈªòËÆ§Ëµ∞ bf16Ôºå‰ΩÜË¶ÅÂÅö‰∏§Â±ÇÊ£ÄÊµãÔºöCUDA ÊîØÊåÅ + cuDNN depthwise conv ÂèØÁî®\n",
    "        if device.type == \"cuda\" and hasattr(torch.cuda, \"is_bf16_supported\") and (not torch.cuda.is_bf16_supported()):\n",
    "            print(\"‚ö†Ô∏è  AMP_DTYPE=bf16 ‰ΩÜÂΩìÂâç CUDA ‰∏çÊîØÊåÅ bf16ÔºåËá™Âä®ÂõûÈÄÄÂà∞ fp16„ÄÇ\", flush=True)\n",
    "            amp_autocast_dtype = torch.float16\n",
    "        else:\n",
    "            amp_autocast_dtype = torch.bfloat16\n",
    "            if not _probe_depthwise_conv(amp_autocast_dtype):\n",
    "                print(\"‚ö†Ô∏è  bf16 ‰∏ã depthwise conv cuDNN Êó†ÂèØÁî®ÂºïÊìéÔºàÂ∏∏ËßÅ‰∫é Windows/ÈÉ®ÂàÜÊ∂àË¥πÁ∫ß GPU/È©±Âä®Ôºâ„ÄÇËá™Âä®ÂõûÈÄÄÂà∞ fp16„ÄÇ\", flush=True)\n",
    "                amp_autocast_dtype = torch.float16\n",
    "\n",
    "    amp_ctx = _make_amp_ctx(amp_autocast_dtype)\n",
    "    scaler = GradScaler(enabled=(device.type == \"cuda\" and amp_autocast_dtype == torch.float16))\n",
    "\n",
    "    # ---- TinyImageNetÔºöÈªòËÆ§ 64√ó64ÔºàÂèØÈÖçÔºâ----\n",
    "    img_size = int(os.environ.get(\"IMG_SIZE\", \"64\"))\n",
    "    val_resize = int(os.environ.get(\"VAL_RESIZE\", str(int(img_size * 1.15))))  # 64 -> 73\n",
    "\n",
    "    # ‰ªçÁî® ImageNet ÂΩí‰∏ÄÂåñÔºåÊñπ‰æøÂêéÁª≠ËøÅÁßª\n",
    "    IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "    IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "    # ËÆ≠ÁªÉÂ¢ûÂº∫ÔºöTiny ‰∏äÂª∫ËÆÆËΩªÈáè‰∏ÄÁÇπ\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.6, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "    ])\n",
    "\n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.Resize(val_resize),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "    ])\n",
    "\n",
    "    # Êï∞ÊçÆÊ†πÁõÆÂΩïÔºöTINYIMAGENET_ROOT ÊåáÂêë tiny-imagenet-200\n",
    "    data_root = os.environ.get(\"TINYIMAGENET_ROOT\", \"./tiny-imagenet-200\")\n",
    "    train_root = os.path.join(data_root, \"train\")\n",
    "    val_root = os.path.join(data_root, \"val\")\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(root=train_root, transform=train_tf)\n",
    "    class_to_idx = train_dataset.class_to_idx  # wnid->idx\n",
    "    val_dataset = TinyImageNetVal(val_root=val_root, class_to_idx=class_to_idx, transform=val_tf)\n",
    "\n",
    "    print(f\"[Stage1-Tiny Single] train: {len(train_dataset)}, val: {len(val_dataset)} | classes={len(train_dataset.classes)}\", flush=True)\n",
    "    if len(train_dataset.classes) != NUM_CLASSES:\n",
    "        print(\n",
    "            f\"‚ö†Ô∏è  WARNING: train classes={len(train_dataset.classes)}Ôºå‰ΩÜ NUM_CLASSES={NUM_CLASSES}„ÄÇ\\n\"\n",
    "            f\"    Â¶ÇÊûú‰Ω†Á°ÆËÆ§Áî®ÁöÑÊòØ Tiny-ImageNet-200ÔºåËØ∑Ê£ÄÊü• TINYIMAGENET_ROOTÔºõÊàñÂ∞Ü NUM_CLASSES ËÆæ‰∏∫ÂÆûÈôÖÁ±ªÂà´Êï∞„ÄÇ\",\n",
    "            flush=True\n",
    "        )\n",
    "\n",
    "    per_gpu_bs = int(os.environ.get(\"PER_GPU_BATCH\", \"32\"))\n",
    "    num_workers = int(os.environ.get(\"NUM_WORKERS\", \"2\"))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=per_gpu_bs,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=(device.type == \"cuda\"),\n",
    "        persistent_workers=(num_workers > 0),\n",
    "        drop_last=False,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=per_gpu_bs,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=(device.type == \"cuda\"),\n",
    "        persistent_workers=(num_workers > 0),\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ---- Ê®°Âûã ----\n",
    "    from vision_lstm6 import VisionLSTM2\n",
    "\n",
    "    pyramid = os.environ.get(\"PYRAMID\", \"half\")  # none/half/half2/full\n",
    "    pair_fusion = os.environ.get(\"PAIR_FUSION\", \"parallel_gated\")\n",
    "    col_every = int(os.environ.get(\"COL_EVERY\", \"2\"))\n",
    "    gamma_init = float(os.environ.get(\"GAMMA_INIT\", \"1e-4\"))\n",
    "    mixer_every = int(os.environ.get(\"MIXER_EVERY\", \"2\"))\n",
    "\n",
    "    # TinyImageNet + use_dwt=True Êó∂ÔºåFeatureExtractor Âú® 'LL' Ê®°Âºè‰∏ã‰ºöÊää H/W ÂèòÊàê IMG_SIZE//2\n",
    "    patch_size = int(os.environ.get(\"PATCH_SIZE\", \"4\"))\n",
    "    stride = int(os.environ.get(\"STRIDE\", str(patch_size)))\n",
    "\n",
    "    # FeatureExtractor ÁöÑÂç∑ÁßØÈÄöÈÅìÈÖçÁΩÆÔºàÈÄóÂè∑ÂàÜÈöîÔºâ\n",
    "    feat_ch_str = os.environ.get(\"FEAT_CH\", \"64,64\")\n",
    "    feature_extractor_channels = [int(x) for x in feat_ch_str.split(\",\") if x.strip()]\n",
    "\n",
    "    pooling = os.environ.get(\"POOLING\", \"global\")  # global | bilateral_avg | bilateral_flatten | (None)\n",
    "    conv_kind = os.environ.get(\"CONV_KIND\", \"2d\")  # 2d | causal1d\n",
    "    conv_kernel = int(os.environ.get(\"CONV_KERNEL\", \"3\"))\n",
    "    legacy_norm = (os.environ.get(\"LEGACY_NORM\", \"0\") == \"1\")\n",
    "    proj_bias = (os.environ.get(\"PROJ_BIAS\", \"1\") == \"1\")\n",
    "    norm_bias = (os.environ.get(\"NORM_BIAS\", \"1\") == \"1\")\n",
    "    drop_path_rate = float(os.environ.get(\"DROP_PATH\", \"0.05\"))\n",
    "    drop_path_decay = (os.environ.get(\"DROP_PATH_DECAY\", \"1\") == \"1\")\n",
    "    use_dwt = (os.environ.get(\"USE_DWT\", \"1\") == \"1\")\n",
    "\n",
    "    model = VisionLSTM2(\n",
    "        dim=int(os.environ.get(\"DIM\", \"384\")),\n",
    "        input_shape=(3, img_size, img_size),\n",
    "        patch_size=patch_size,\n",
    "        depth=int(os.environ.get(\"DEPTH\", \"8\")),\n",
    "        output_shape=(NUM_CLASSES,),\n",
    "        mode=\"classifier\",\n",
    "        pooling=pooling,\n",
    "        drop_path_rate=drop_path_rate,\n",
    "        drop_path_decay=drop_path_decay,\n",
    "        stride=stride,\n",
    "        legacy_norm=legacy_norm,\n",
    "        conv_kind=conv_kind,\n",
    "        conv_kernel_size=conv_kernel,\n",
    "        proj_bias=proj_bias,\n",
    "        norm_bias=norm_bias,\n",
    "        feature_extractor_channels=feature_extractor_channels,\n",
    "        use_dwt=use_dwt,\n",
    "\n",
    "        # ÈáëÂ≠óÂ°î/ËûçÂêà/Â±ÄÈÉ® mixer\n",
    "        pyramid=pyramid,\n",
    "        mixer_every=mixer_every,\n",
    "        pair_fusion=pair_fusion,\n",
    "        col_every=col_every,\n",
    "        gamma_init=gamma_init,\n",
    "    ).to(device)\n",
    "\n",
    "    # ---- ÊÅ¢Â§çÔºàÂèØÈÄâÔºâ----\n",
    "    resume_ckpt = os.environ.get(\"RESUME_CKPT\", \"\").strip()\n",
    "    if resume_ckpt and os.path.isfile(resume_ckpt):\n",
    "        state = torch.load(resume_ckpt, map_location=\"cpu\")\n",
    "        missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "        print(f\"[Stage1-Tiny Single] Resume from {resume_ckpt} | missing={len(missing)}, unexpected={len(unexpected)}\", flush=True)\n",
    "    elif resume_ckpt:\n",
    "        print(f\"[Stage1-Tiny Single] RESUME_CKPT {resume_ckpt} not found, train from scratch\", flush=True)\n",
    "    else:\n",
    "        print(\"[Stage1-Tiny Single] Train from scratch\", flush=True)\n",
    "\n",
    "    # branch alphaÔºöÂÖàÂÖ≥Êéâ\n",
    "    if hasattr(model, \"head_adapter\") and hasattr(model.head_adapter, \"alpha\"):\n",
    "        with torch.no_grad():\n",
    "            model.head_adapter.alpha.fill_(0.0)\n",
    "\n",
    "    # ---- Ë∂ÖÂèÇÊï∞ ----\n",
    "    num_epochs = int(os.environ.get(\"EPOCHS\", \"100\"))\n",
    "    warmup_epochs = int(os.environ.get(\"WARMUP_EPOCHS\", \"5\"))\n",
    "    accum_steps = int(os.environ.get(\"ACCUM_STEPS\", \"1\"))\n",
    "\n",
    "    # ‚úÖ ÈªòËÆ§ÂÖ≥Èó≠Ê∑∑ÂêàÂ¢ûÂº∫ÔºöÊõ¥ÈÄÇÂêà Tiny ‰∏äÂø´ÈÄüËø≠‰ª£ÁªìÊûÑ\n",
    "    mix_prob = float(os.environ.get(\"MIX_PROB\", \"0.0\"))  # 0.0 = off\n",
    "    mixup_alpha = float(os.environ.get(\"MIXUP\", \"0.2\"))\n",
    "    cutmix_alpha = float(os.environ.get(\"CUTMIX\", \"1.0\"))\n",
    "    switch_prob = float(os.environ.get(\"SWITCH_PROB\", \"0.5\"))\n",
    "    label_smooth = float(os.environ.get(\"LABEL_SMOOTH\", \"0.1\"))\n",
    "\n",
    "    ema_decay = float(os.environ.get(\"EMA_DECAY\", \"0.9999\"))\n",
    "\n",
    "    global_batch = per_gpu_bs * accum_steps\n",
    "    base_lr = float(os.environ.get(\"BASE_LR\", \"2e-4\"))  # Êõ¥Á®≥ÁöÑÈªòËÆ§ÂÄºÔºöÈÄÇÈÖçÁ¨îËÆ∞Êú¨/Â∞è batch\n",
    "    weight_decay = float(os.environ.get(\"WEIGHT_DECAY\", \"0.05\"))\n",
    "    clip_grad = float(os.environ.get(\"CLIP_GRAD\", \"1.0\"))\n",
    "    BRANCH_LR_SCALE = float(os.environ.get(\"BRANCH_LR_SCALE\", \"1.0\"))\n",
    "\n",
    "    print(\n",
    "        f\"[Config] img={img_size}, epochs={num_epochs}, warmup_epochs={warmup_epochs}, \"\n",
    "        f\"bs={per_gpu_bs}, accum={accum_steps}, global_bs={global_batch}, \"\n",
    "        f\"lr={base_lr:.2e}, wd={weight_decay}, clip={clip_grad}, amp={amp_dtype_req} | \"\n",
    "        f\"mix_prob={mix_prob}, mixup={mixup_alpha}, cutmix={cutmix_alpha}, ls={label_smooth}\",\n",
    "        flush=True\n",
    "    )\n",
    "\n",
    "    param_groups = build_param_groups(model, base_lr, weight_decay, BRANCH_LR_SCALE)\n",
    "    optimizer = torch.optim.AdamW(param_groups, lr=base_lr)\n",
    "\n",
    "    # LR scheduleÔºöLinear warmup + cosineÔºàÊåâ optimizer step Êõ¥Êñ∞Ôºâ\n",
    "    updates_per_epoch = max(1, math.ceil(len(train_loader) / accum_steps))\n",
    "    num_training_steps = num_epochs * updates_per_epoch\n",
    "    warmup_steps = warmup_epochs * updates_per_epoch\n",
    "\n",
    "    from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "    sch1 = LinearLR(optimizer, start_factor=0.1, total_iters=max(1, warmup_steps))\n",
    "    sch2 = CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=max(1, num_training_steps - warmup_steps),\n",
    "        eta_min=base_lr * 3e-2\n",
    "    )\n",
    "    scheduler = SequentialLR(optimizer, schedulers=[sch1, sch2], milestones=[warmup_steps])\n",
    "\n",
    "    ema_model = create_ema_model(model).to(device)\n",
    "\n",
    "    # branch alpha Âä®ÊÄÅÁ≠ñÁï•\n",
    "    BRANCH_START = int(os.environ.get(\"BRANCH_ALPHA_START\", \"10\"))\n",
    "    BRANCH_RAMP = int(os.environ.get(\"BRANCH_RAMP\", \"10\"))\n",
    "    BRANCH_MAX = float(os.environ.get(\"BRANCH_ALPHA_MAX\", \"1e-2\"))\n",
    "\n",
    "    best_acc = 0.0\n",
    "    pretrain_ckpt = os.environ.get(\"OUT_CKPT\", \"stage1_tiny_ema_best.pth\")\n",
    "    log_every = int(os.environ.get(\"LOG_EVERY\", \"50\"))\n",
    "\n",
    "    # ---- ËÆ≠ÁªÉÂæ™ÁéØ ----\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Âä®ÊÄÅ branch alpha\n",
    "        a = get_branch_alpha(epoch, BRANCH_START, BRANCH_RAMP, BRANCH_MAX)\n",
    "        if hasattr(model, \"head_adapter\") and hasattr(model.head_adapter, \"alpha\"):\n",
    "            with torch.no_grad():\n",
    "                model.head_adapter.alpha.fill_(a)\n",
    "                if hasattr(ema_model, \"head_adapter\") and hasattr(ema_model.head_adapter, \"alpha\"):\n",
    "                    ema_model.head_adapter.alpha.fill_(a)\n",
    "\n",
    "        # Âä®ÊÄÅÊâìÂºÄ branch_decay ÁöÑ weight_decay\n",
    "        for g in optimizer.param_groups:\n",
    "            if g.get(\"is_branch\", False) and (not g.get(\"is_no_wd\", False)):\n",
    "                g[\"weight_decay\"] = (weight_decay if epoch >= BRANCH_START else 0.0)\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        acc_hist = []\n",
    "        opt_steps = 0\n",
    "\n",
    "        for i, (imgs, target) in enumerate(train_loader, start=1):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "\n",
    "            # mixup/cutmixÔºàÈªòËÆ§ÂÖ≥Èó≠ÔºöMIX_PROB=0Ôºâ\n",
    "            imgs_m, y_a, y_b, lam, is_mixed = apply_mixup_cutmix(\n",
    "                imgs, target,\n",
    "                mixup_alpha=mixup_alpha,\n",
    "                cutmix_alpha=cutmix_alpha,\n",
    "                prob=mix_prob,\n",
    "                switch_prob=switch_prob\n",
    "            )\n",
    "\n",
    "            with amp_ctx:\n",
    "                logits = model(imgs_m)\n",
    "                loss = soft_target_loss(\n",
    "                    logits, y_a, y_b, lam,\n",
    "                    label_smooth=label_smooth,\n",
    "                    mixed=is_mixed\n",
    "                ) / accum_steps\n",
    "\n",
    "            if scaler.is_enabled():\n",
    "                scaler.scale(loss).backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            running_loss += loss.item() * accum_steps\n",
    "\n",
    "            # ËÆ≠ÁªÉÊåáÊ†áÔºö‰∏çÊ∑∑ÂêàÂ∞± hard accÔºõÊ∑∑ÂêàÂ∞± soft accÔºàÊõ¥Ë¥¥Âêà mixup/cutmixÔºâ\n",
    "            with torch.no_grad():\n",
    "                pred = logits.argmax(1)\n",
    "                if not is_mixed:\n",
    "                    acc = (pred == y_a).float().mean().item()\n",
    "                else:\n",
    "                    # soft acc: probability mass assigned to predicted class\n",
    "                    bs = logits.size(0)\n",
    "                    soft_targets = torch.zeros((bs, logits.size(1)), device=logits.device, dtype=logits.dtype)\n",
    "                    soft_targets.scatter_(1, y_a.unsqueeze(1), lam)\n",
    "                    soft_targets.scatter_(1, y_b.unsqueeze(1), 1.0 - lam)\n",
    "                    acc = soft_targets.gather(1, pred.unsqueeze(1)).squeeze(1).mean().item()\n",
    "                acc_hist.append(acc)\n",
    "\n",
    "            do_step = (i % accum_steps == 0)\n",
    "            if do_step:\n",
    "                if scaler.is_enabled():\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    if clip_grad > 0:\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    if clip_grad > 0:\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "                    optimizer.step()\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                scheduler.step()\n",
    "                opt_steps += 1\n",
    "\n",
    "                update_ema(model, ema_model, ema_decay)\n",
    "\n",
    "            if (log_every > 0) and (i % log_every == 0):\n",
    "                avg_acc = float(sum(acc_hist) / max(1, len(acc_hist)))\n",
    "                print(\n",
    "                    f\"  iter {i:5d}/{len(train_loader)} | loss {loss.item()*accum_steps:.4f} | \"\n",
    "                    f\"acc {avg_acc:.3f} | lr {scheduler.get_last_lr()[0]:.2e}\",\n",
    "                    flush=True\n",
    "                )\n",
    "\n",
    "        # ‚úÖ Â§ÑÁêÜÂ∞æÂ∑¥Ôºölen(loader) ‰∏çÊòØ accum_steps ÁöÑÊï¥Êï∞ÂÄçÊó∂ÔºåÊúÄÂêé‰∏ÄÊÆµÊ¢ØÂ∫¶‰πüË¶Å step\n",
    "        if (len(train_loader) % accum_steps) != 0:\n",
    "            if scaler.is_enabled():\n",
    "                scaler.unscale_(optimizer)\n",
    "                if clip_grad > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                if clip_grad > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step()\n",
    "            opt_steps += 1\n",
    "            update_ema(model, ema_model, ema_decay)\n",
    "\n",
    "        # ---- È™åËØÅÔºàEMA Ê®°ÂûãÔºâ----\n",
    "        ema_model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.inference_mode():\n",
    "            for imgs, target in val_loader:\n",
    "                imgs = imgs.to(device, non_blocking=True)\n",
    "                target = target.to(device, non_blocking=True)\n",
    "                with amp_ctx:\n",
    "                    logits = ema_model(imgs)\n",
    "                    loss_v = F.cross_entropy(logits, target)\n",
    "                val_loss += loss_v.item() * target.size(0)\n",
    "                pred = logits.argmax(1)\n",
    "                val_correct += (pred == target).sum().item()\n",
    "                val_total += target.size(0)\n",
    "\n",
    "        val_loss_g = val_loss / max(val_total, 1)\n",
    "        val_acc_g = val_correct / max(val_total, 1)\n",
    "\n",
    "        train_loss_epoch = running_loss / max(1, len(train_loader))\n",
    "        train_acc_epoch = float(sum(acc_hist) / max(1, len(acc_hist)))\n",
    "\n",
    "        print(f\"[Epoch {epoch:03d}] Train loss={train_loss_epoch:.4f}, acc={train_acc_epoch:.4f} | opt_steps={opt_steps}\", flush=True)\n",
    "        print(f\"[Epoch {epoch:03d}] Val   loss={val_loss_g:.4f}, acc={val_acc_g:.4f}, lr={scheduler.get_last_lr()[0]:.2e}\", flush=True)\n",
    "\n",
    "        if val_acc_g > best_acc:\n",
    "            best_acc = val_acc_g\n",
    "            torch.save(ema_model.state_dict(), pretrain_ckpt)\n",
    "            print(f\"  üåü New best saved @ {pretrain_ckpt} (acc={best_acc:.4f})\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34584713-a847-4b1f-8e00-61cbb9cc3ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage1-Tiny Single] train: 100000, val: 10000 | classes=200\n",
      "[Stage1-Tiny Single] Train from scratch\n",
      "[Config] img=64, epochs=100, warmup_epochs=5, bs=32, accum=1, global_bs=32, lr=2.00e-04, wd=0.05, clip=1.0, amp=fp16 | mix_prob=0.0, mixup=0.2, cutmix=1.0, ls=0.1\n",
      "  iter    50/3125 | loss 5.2867 | acc 0.013 | lr 2.06e-05\n",
      "  iter   100/3125 | loss 5.2847 | acc 0.012 | lr 2.12e-05\n",
      "  iter   150/3125 | loss 5.2747 | acc 0.013 | lr 2.17e-05\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74463dc8-1234-4e31-a882-14073b34f783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
